{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":19626,"status":"ok","timestamp":1706354797411,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"Bpg_-yP5NDfP"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from scipy.stats import spearmanr\n","from sklearn.model_selection import train_test_split\n","from sklearn.cluster import KMeans\n","from sklearn.semi_supervised import LabelSpreading\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score, precision_score, f1_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sentence_transformers import SentenceTransformer\n","import json\n","import re\n","import time\n","import sentencepiece\n","from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM, PegasusForConditionalGeneration, PegasusTokenizer, pipeline\n","import torch\n","random_seed=42"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1706354797412,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"d9UDSOg4tXbm"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1706354797412,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"XWLwR2eEOW1_"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":842,"status":"ok","timestamp":1706354798248,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"XjhtjcWSNCs0"},"outputs":[],"source":["# df = pd.read_json(r'/content/drive/MyDrive/HIT/SHROOM/data/val.model-aware.v2.json',lines=False)\n","df = pd.read_json(r'/content/drive/MyDrive/HIT/SHROOM/data/test.model-aware.json',lines=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1706354798248,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"ZAJ1SRjWNtTi"},"outputs":[],"source":["df_dm = df[df['task']=='DM']\n","df_dm.index = np.arange(df_dm.shape[0])\n","\n","df_mt = df[df['task']=='MT']\n","df_mt.index = np.arange(df_mt.shape[0])\n","\n","df_pg = df[df['task']=='PG']\n","df_pg.index = np.arange(df_pg.shape[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twMSh_S9JhOv"},"outputs":[],"source":["# DM tgt ltg/flan-t5-definition-en-base\n","# MT either facebook/nllb-200-distilled-600M\n","# PG src tuner007/pegasus_paraphrase"]},{"cell_type":"markdown","metadata":{"id":"JzW4sQEDOIsx"},"source":["DM"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12218,"status":"ok","timestamp":1706354817463,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"uzxoYUuhaH-k","outputId":"e1d79019-8f03-41cc-8561-822f7891a3e9"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import torch\n","\n","model = T5ForConditionalGeneration.from_pretrained(\"ltg/flan-t5-definition-en-base\")\n","tokenizer = T5Tokenizer.from_pretrained(\"ltg/flan-t5-definition-en-base\")\n","model.to(device)\n","\n","def DM(input_text):\n","\n","  inputs = tokenizer.encode_plus(input_text, return_tensors=\"pt\")\n","  inputs = inputs.to(device)\n","\n","  decoder_input_ids = torch.tensor([[tokenizer.pad_token_id]])\n","  decoder_input_ids = decoder_input_ids.to(device)\n","\n","  token_probs = []\n","  token_entropies = []\n","\n","\n","  # Loop to generate each token\n","   for i in range(400): # Generate up to 400 tokens\n","       # Get the output of the model\n","       outputs = model(**inputs, decoder_input_ids=decoder_input_ids)\n","\n","       # Get logits\n","       logits = outputs.logits\n","\n","       #Convert logits to probabilities\n","       probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n","\n","       # Calculate entropy\n","       entropy = -torch.sum(probs * torch.log(probs), dim=-1)\n","\n","       # Get the index with the highest probability\n","       _, predicted_index = torch.max(probs, dim=-1)\n","\n","       #Convert index to text\n","       predicted_token = tokenizer.decode(predicted_index)\n","\n","       # If the generated token is a terminator, then end the generation\n","       if predicted_token == tokenizer.eos_token:\n","           break\n","\n","       # Add the generated token and its probability to the list\n","       token_probs.append(torch.max(probs).cpu().item())\n","       token_entropies.append(entropy.cpu().item())\n","\n","\n","\n","       # Add the generated token to the input of the decoder\n","       decoder_input_ids = torch.cat([decoder_input_ids, predicted_index.unsqueeze(-1)], dim=-1)\n","\n","\n","\n","\n","\n","\n","\n","  # Loop to generate each token\n","  for i in range(400):  # Generate up to 400 tokens\n","      # Get the output of the model\n","      outputs = model(**inputs, decoder_input_ids=decoder_input_ids)\n","\n","      # 获取logits\n","      logits = outputs.logits\n","\n","      # Convert logits to probabilities\n","      probs = torch.nn.functional.softmax(logits[:, -1, :], dim=-1)\n","\n","      # Calculate entropy\n","      entropy = -torch.sum(probs * torch.log(probs), dim=-1)\n","\n","      # Get the index with the highest probability\n","      _, predicted_index = torch.max(probs, dim=-1)\n","\n","      # Convert index to text\n","      predicted_token = tokenizer.decode(predicted_index)\n","\n","      # If the generated token is a terminator, then end the generation\n","      if predicted_token == tokenizer.eos_token:\n","          break\n","\n","      # Add the generated token and its probability to the list\n","      token_probs.append(torch.max(probs).cpu().item())\n","      token_entropies.append(entropy.cpu().item())\n","\n","\n","\n","      # Add the generated token to the input of the decoder\n","      decoder_input_ids = torch.cat([decoder_input_ids, predicted_index.unsqueeze(-1)], dim=-1)\n","\n","  stats = {\n","        'token_prob_min': 1-np.min(token_probs),\n","        'token_prob_max': 1-np.max(token_probs),\n","        'token_prob_mean': 1-np.mean(token_probs),\n","        'token_entropy_min': np.min(token_entropies),\n","        'token_entropy_max': np.max(token_entropies),\n","        'token_entropy_mean': np.mean(token_entropies),\n","    }\n","\n","  return stats\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZga6w4uYf0e"},"outputs":[],"source":["def apply_DM(df):\n","    df_stats = df['src'].apply(DM).apply(pd.Series)\n","    for stat in ['token_prob_min', 'token_prob_max', 'token_prob_mean',\n","            'token_entropy_min', 'token_entropy_max', 'token_entropy_mean']:\n","        df[stat] = df_stats[stat]\n","    return df\n","\n","df_dm = apply_DM(df_dm)\n","\n","for stat in ['token_prob_min', 'token_prob_max', 'token_prob_mean']:\n","  print(\"\\n\\n****************\", stat)\n","  for zhiding in np.arange(0.1,1,0.02):\n","    df_dm['label_pre'] = df_dm[stat].apply(lambda x: 1 if x>zhiding else 0)\n","    print('阈值：',round(zhiding,2),' 准确率：',round(accuracy_score(df_dm['label'], df_dm['label_pre']),2))\n","  print('Spearman：', round(spearmanr(df_dm[stat], df_dm['p(Hallucination)'])[0], 2))\n","\n","for stat in ['token_entropy_min', 'token_entropy_max', 'token_entropy_mean']:\n","  print(\"\\n\\n****************\", stat)\n","  for zhiding in np.arange(0.1,10,0.1):\n","    df_dm['label_pre'] = df_dm[stat].apply(lambda x: 1 if x>zhiding else 0)\n","    print('阈值：',round(zhiding,2),' 准确率：',round(accuracy_score(df_dm['label'], df_dm['label_pre']),2))\n","  print('Spearman：', round(spearmanr(df_dm[stat], df_dm['p(Hallucination)'])[0], 2))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1706354819642,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"ARAH-GrYdbwi"},"outputs":[],"source":["def calibrate_probability(p, p_value):\n","    if p == p_value:\n","        return 0.5\n","    elif p > p_value:\n","        return 0.5 + (p - p_value) * (1 - 0.5) / (1 - p_value)\n","    else:  # p < p_value\n","        return 0 + (p - 0) * (0.5 - 0) / (p_value - 0)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706354819643,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"mioYKU-qazI2"},"outputs":[],"source":["def calibrate_probability_entropy(p, p_value, max):\n","    if p == p_value:\n","        return 0.5\n","    elif p >= max:\n","        return 1\n","    elif p > p_value:\n","        return 0.5 + (p - p_value) * (1 - 0.5) / (max - p_value)\n","    else:  # p < p_value\n","        return 0 + (p - 0) * (0.5 - 0) / (p_value - 0)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1706354819643,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"WU9N-Jp9xhWt"},"outputs":[],"source":["df_all1 = pd.DataFrame()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijoWjqvWGg6S"},"outputs":[],"source":["# token_prob_min\n","# Threshold: 0.76 Accuracy: 0.63**\n","# token_prob_max\n","# Threshold: 0.26 Accuracy: 0.54\n","# token_prob_mean\n","# Threshold: 0.3 Accuracy: 0.59**\n","# token_entropy_min\n","# Threshold: 0.8 Accuracy: 0.54\n","# token_entropy_max\n","# Threshold: 3.8 Accuracy: 0.64**\n","# token_entropy_mean\n","# Threshold: 1.7 Accuracy: 0.64**\n","\n","# token_entropy_mean is selected based on the effect of the verification set."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":313888,"status":"ok","timestamp":1706355135664,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"xe3LeYvCZyDW"},"outputs":[],"source":["def apply_DM(df):\n","    df_stats = df['src'].apply(DM).apply(pd.Series)\n","    for stat in ['token_prob_min', 'token_prob_max', 'token_prob_mean',\n","            'token_entropy_min', 'token_entropy_max', 'token_entropy_mean']:\n","        df[stat] = df_stats[stat]\n","    return df\n","\n","df_dm = apply_DM(df_dm)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":704,"status":"ok","timestamp":1706355314210,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"kkIew3FiaqFt","outputId":"9a2c3741-158d-46bf-b8c4-2876b6ca0ac0"},"outputs":[{"data":{"text/plain":["count    554.000000\n","mean       1.711624\n","std        0.580928\n","min        0.300135\n","50%        1.738078\n","98%        2.724807\n","max        4.734089\n","Name: token_entropy_mean, dtype: float64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df_dm['token_entropy_mean'].describe(percentiles=[.98])"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":590,"status":"ok","timestamp":1706355330290,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"mCS4rZAmY6sj"},"outputs":[],"source":["p_value1 = 1.7\n","max = 2.7\n","df_dm['pred'] = df_dm['token_entropy_mean'].apply(lambda x: calibrate_probability_entropy(x, p_value1, max))"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":578,"status":"ok","timestamp":1706355374924,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"C9hMvjLwrKlv","outputId":"1b39a2cc-e875-4256-ba37-e4c5f0bd23c3"},"outputs":[{"data":{"text/plain":["Index(['id', 'src', 'tgt', 'hyp', 'task', 'model', 'token_prob_min',\n","       'token_prob_max', 'token_prob_mean', 'token_entropy_min',\n","       'token_entropy_max', 'token_entropy_mean', 'pred'],\n","      dtype='object')"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["df_dm.columns"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":901,"status":"ok","timestamp":1706355399570,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"0sOwOmOdrxAs"},"outputs":[],"source":["df_dm = df_dm[['id', 'src', 'tgt', 'hyp', 'task', 'model',  'pred']]"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706355399571,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"tqScRfVxYxYE"},"outputs":[],"source":["df_all1 = pd.concat([df_all1, df_dm])"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706355400502,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"-5kTMS-_chAX","outputId":"321e70c0-5f9d-4661-ca3c-c100bad565e1"},"outputs":[{"data":{"text/plain":["Index(['id', 'src', 'tgt', 'hyp', 'task', 'model', 'pred'], dtype='object')"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df_all1.columns"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":710,"status":"ok","timestamp":1706355407729,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"Cj4FQGtRuMYc"},"outputs":[],"source":["del model, tokenizer\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"1HVQh1OxOMrr"},"source":["MT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rhbyxCn5zQH"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","model_name = \"facebook/nllb-200-distilled-600M\"\n","# tokenizer1 = AutoTokenizer.from_pretrained(model_name, src_lang=\"zho_Hans\")\n","tokenizer1 = AutoTokenizer.from_pretrained(model_name, src_lang=\"eng_Latn\")\n","tokenizer2 = AutoTokenizer.from_pretrained(model_name, src_lang=\"eng_Latn\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","model.to(device)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706355452541,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"kgzNoEuOzkCa"},"outputs":[],"source":["def MT(input_text):\n","    inputs = tokenizer1.encode(input_text, return_tensors='pt')\n","    inputs = inputs.to(device)\n","    outputs = model.generate(inputs, forced_bos_token_id=tokenizer1.lang_code_to_id[\"eng_Latn\"], output_scores=True, return_dict_in_generate=True)\n","\n","    token_probs = []\n","    token_entropies = []\n","    for i in np.arange(1,len(outputs['scores'])-1):\n","        probs = outputs['scores'][i].softmax(dim=-1)[0]\n","        token_probs.append(torch.max(probs).item())\n","        token_entropies.append(-torch.sum(probs * torch.log(probs)).item())\n","\n","    stats = {\n","        'token_prob_min': 1-np.min(token_probs),\n","        'token_prob_max': 1-np.max(token_probs),\n","        'token_prob_mean': 1-np.mean(token_probs),\n","        'token_entropy_min': np.min(token_entropies),\n","        'token_entropy_max': np.max(token_entropies),\n","        'token_entropy_mean': np.mean(token_entropies),\n","    }\n","\n","    return stats"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706352891613,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"qE5h0ESzHQNf","outputId":"7a61f253-615e-4867-ff3c-2d7ccb8082c9"},"outputs":[{"data":{"text/plain":["{'token_prob_min': 0.4403417706489563,\n"," 'token_prob_max': 0.18828970193862915,\n"," 'token_prob_mean': 0.3134673237800598,\n"," 'token_entropy_min': 1.7458938360214233,\n"," 'token_entropy_max': 3.8632514476776123,\n"," 'token_entropy_mean': 2.651001731554667}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["MT(\"请介绍你自己\")\n","# prob:min mean\n","# entropy:max mean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZn2Kql9zvWU"},"outputs":[],"source":["def apply_MT(df):\n","    df_stats = df['src'].apply(MT)\n","    for stat in ['token_prob_min', 'token_prob_max', 'token_prob_mean', 'token_entropy_min', 'token_entropy_max', 'token_entropy_mean']:\n","        df[stat] = df_stats.apply(lambda x: x[stat])\n","    return df\n","\n","df_mt = apply_MT(df_mt)\n","\n","# model prediction\n","for stat in ['token_prob_min', 'token_prob_max', 'token_prob_mean']:\n","  print(\"\\n\\n****************\", stat)\n","  for zhiding in np.arange(0.1,1,0.02):\n","    df_mt['label_pre'] = df_mt[stat].apply(lambda x: 1 if x>zhiding else 0)\n","    print('阈值：',round(zhiding,2),' 准确率：',round(accuracy_score(df_mt['label'], df_mt['label_pre']),2))\n","  print('Spearman：', round(spearmanr(df_mt[stat], df_mt['p(Hallucination)'])[0], 2))\n","\n","for stat in ['token_entropy_min', 'token_entropy_max', 'token_entropy_mean']:\n","  print(\"\\n\\n****************\", stat)\n","  for zhiding in np.arange(0.1,10,0.1):\n","    df_mt['label_pre'] = df_mt[stat].apply(lambda x: 1 if x>zhiding else 0)\n","    print('阈值：',round(zhiding,2),' 准确率：',round(accuracy_score(df_mt['label'], df_mt['label_pre']),2))\n","  print('Spearman：', round(spearmanr(df_mt[stat], df_mt['p(Hallucination)'])[0], 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"32z_7OhMlC89"},"outputs":[],"source":["# token_prob_min\n","# Threshold： 0.88  Accuracy： 0.62\n","# token_prob_max\n","# Threshold： 0.1  Accuracy： 0.59\n","# token_prob_mean\n","# Threshold： 0.46  Accuracy： 0.62\n","# token_entropy_min\n","# Threshold： 1.0  Accuracy： 0.6\n","# token_entropy_max\n","# Threshold： 7.3  Accuracy： 0.61\n","# token_entropy_mean\n","# Threshold： 3.4  Accuracy： 0.64 **\n","# token_entropy_mean is selected based on the effect of the verification set."]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":520977,"status":"ok","timestamp":1706356008125,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"rCr8Wdd-HGXR"},"outputs":[],"source":["def apply_MT(df):\n","    df_stats = df['src'].apply(MT).apply(pd.Series)\n","    for stat in ['token_prob_min', 'token_prob_max', 'token_prob_mean',\n","            'token_entropy_min', 'token_entropy_max', 'token_entropy_mean']:\n","        df[stat] = df_stats[stat]\n","    return df\n","\n","df_mt = apply_MT(df_mt)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":822,"status":"ok","timestamp":1706356077651,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"Ws83zG04j69Q","outputId":"a708780d-4fb8-4250-ffe8-49f93167503a"},"outputs":[{"data":{"text/plain":["count    563.000000\n","mean       3.485392\n","std        0.971581\n","min        0.941815\n","50%        3.432197\n","98%        5.509425\n","max        5.787091\n","Name: token_entropy_mean, dtype: float64"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["df_mt['token_entropy_mean'].describe(percentiles=[.98])"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":573,"status":"ok","timestamp":1706356102072,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"FOGrbymdj9ol"},"outputs":[],"source":["p_value1 = 3.4\n","max = 5.5\n","df_mt['pred'] = df_mt['token_entropy_mean'].apply(lambda x: calibrate_probability_entropy(x ,p_value1, max))"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1706356103089,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"_beNeGBdtxin"},"outputs":[],"source":["df_mt = df_mt[['id', 'src', 'tgt', 'hyp', 'task', 'model',  'pred']]"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1706356103852,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"1mzFHFPhkBwA"},"outputs":[],"source":["df_all1 = pd.concat([df_all1, df_mt])"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706356124184,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"VhfF_edXv_24","outputId":"4ba6348d-0948-4eed-f3bc-4f001fe37bdb"},"outputs":[{"data":{"text/plain":["(1125, 7)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df_all1.shape"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":900,"status":"ok","timestamp":1706356113509,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"jVu3qiBEt9AO"},"outputs":[],"source":["del model, tokenizer1, tokenizer2\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"Iw8mFcRcOOHG"},"source":["PG"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":911,"status":"ok","timestamp":1706356131111,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"biLEptoauuGJ"},"outputs":[],"source":["from openai import OpenAI\n","import numpy as np\n","\n","client = OpenAI()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MFX5-dnND7OC"},"outputs":[],"source":["import torch\n","from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n","\n","model_name = 'tuner007/pegasus_paraphrase'\n","\n","tokenizer = PegasusTokenizer.from_pretrained(model_name)\n","model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n","\n","def get_response(input_text, num_return_sequences, num_beams):\n","    batch = tokenizer([input_text], truncation=True, padding='longest', max_length=200, return_tensors=\"pt\").to(device)\n","    translated = model.generate(**batch, max_length=200, num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n","    tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n","    return tgt_text, translated"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":643,"status":"ok","timestamp":1706357494257,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"djtHkNOzuGGp"},"outputs":[],"source":["def PG(context):\n","  while True:\n","    try:\n","      print(1)\n","      num_beams = 5\n","      num_return_sequences = 5\n","      responses, translated = get_response(context, num_return_sequences, num_beams)\n","      answer = []\n","      for response in responses:\n","\n","        content = f\"Context: {response}\\n\\Sentence: {context}\\n\\Is the sentence supported by the context above?\\n\\Answer Yes or No:\"\n","\n","        response = client.chat.completions.create(\n","            model=\"gpt-4-1106-preview\",\n","            messages=[{\"role\": \"user\", \"content\": content}],\n","            temperature=0,\n","            max_tokens=10,\n","            n=1\n","        )\n","\n","        for i in np.arange(len(response.choices)):\n","          if 'yes' in response.choices[i].message.content.lower():\n","            answer.append(0)\n","          elif 'no' in response.choices[i].message.content.lower():\n","            answer.append(1)\n","          else:\n","            print(i, '***', response.choices[i].message.content.lower())\n","            answer.append(1)\n","          # print(response.choices[i].message.content)\n","\n","      time.sleep(0.3)\n","      return np.mean(answer)\n","    except Exception as e:\n","      print(e)\n","      time.sleep(5)\n"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8196,"status":"ok","timestamp":1706357471028,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"e8S_BEeCwHW3","outputId":"d8434d09-13a2-4b8c-c0c6-3c23d23bd523"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]},{"data":{"text/plain":["0.0"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["PG(\"hello\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":868972,"status":"ok","timestamp":1706359119183,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"-PmLg-7OwG4g","outputId":"52e3d596-99be-4361-9adf-4ec32e258ed4"},"outputs":[],"source":["df_pg['pred'] = df_pg['src'].apply(PG)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6aadzYLXzdC"},"outputs":[],"source":["num_beams = 5\n","num_return_sequences = 5\n","context = \"The ultimate test of your knowledge is your capacity to convey it to another.\"\n","response, translated = get_response(context,num_return_sequences,num_beams)\n","response"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1706357454448,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"q_IyKT1gpgQt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1706359119186,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"-rzDUQJhozk6"},"outputs":[],"source":["df_pg = df_pg[['id', 'src', 'tgt', 'hyp', 'task', 'model',  'pred']]"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1706359119186,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"ByP77B8jnpxa"},"outputs":[],"source":["df_all1 = pd.concat([df_all1, df_pg])"]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1706359119187,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"4ovnNuk40WRu"},"outputs":[],"source":["# final\n","df_all1 = df_all1.sort_values('id')\n","df_all1.index=np.arange(df_all1.shape[0])"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1706359119187,"user":{"displayName":"wei liu","userId":"02108141993961440306"},"user_tz":-480},"id":"_5M2d40zvYx2"},"outputs":[],"source":["# model result\n","df_all1['p(Hallucination)'] = df_all1['pred']\n","df_all1['label'] = (df_all1['pred']>=0.5).astype(int).tolist()\n","\n","test_data_aware_all = df_all1\n","\n","path_val_model_aware_output = \"test.model-aware.json\"\n","output_json = []\n","for i in np.arange(test_data_aware_all.shape[0]):\n","    output_label = 'Hallucination' if test_data_aware_all.loc[i,'label'] == 1 else 'Not Hallucination'\n","    prob=test_data_aware_all.loc[i,'p(Hallucination)']\n","    id=test_data_aware_all.loc[i,'id']\n","    item_to_json = {\"label\":output_label, \"p(Hallucination)\":np.float64(prob), \"id\":int(id)}\n","    output_json.append(item_to_json)\n","f = open(path_val_model_aware_output, 'w', encoding='utf-8')\n","json.dump(output_json, f)\n","f.close()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
